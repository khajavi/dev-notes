# Apache Spark

* [Common Spark Troubleshooting](http://www.datastax.com/dev/blog/common-spark-troubleshooting)
* [What controls how much of a Spark Cluster is given to an application?](https://stackoverflow.com/questions/27944948/what-controls-how-much-of-a-spark-cluster-is-given-to-an-application)
* [Spark Tutorial](http://lintool.github.io/SparkTutorial/)

# Examples

```scala
    .set("spark.executor.memory", "lg")
    .set("spark.cores.max", "1")
```
